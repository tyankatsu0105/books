<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->

- [生成AI](#%E7%94%9F%E6%88%90ai)
- [出力形式](#%E5%87%BA%E5%8A%9B%E5%BD%A2%E5%BC%8F)
- [Code Interpreter](#code-interpreter)
  - [Open Interpreter](#open-interpreter)
- [ハルシネーションの回避に注意](#%E3%83%8F%E3%83%AB%E3%82%B7%E3%83%8D%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E3%81%AE%E5%9B%9E%E9%81%BF%E3%81%AB%E6%B3%A8%E6%84%8F)
- [ChatGPTと従来のちゃんとボットとの違い](#chatgpt%E3%81%A8%E5%BE%93%E6%9D%A5%E3%81%AE%E3%81%A1%E3%82%83%E3%82%93%E3%81%A8%E3%83%9C%E3%83%83%E3%83%88%E3%81%A8%E3%81%AE%E9%81%95%E3%81%84)
- [LLM](#llm)
- [Transformer](#transformer)
- [スケール則](#%E3%82%B9%E3%82%B1%E3%83%BC%E3%83%AB%E5%89%87)
- [プロンプトエンジニアリング](#%E3%83%97%E3%83%AD%E3%83%B3%E3%83%97%E3%83%88%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%83%AA%E3%83%B3%E3%82%B0)
  - [プロンプトエンジニアリングのテクニック](#%E3%83%97%E3%83%AD%E3%83%B3%E3%83%97%E3%83%88%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%83%AA%E3%83%B3%E3%82%B0%E3%81%AE%E3%83%86%E3%82%AF%E3%83%8B%E3%83%83%E3%82%AF)
    - [指示を具体的に](#%E6%8C%87%E7%A4%BA%E3%82%92%E5%85%B7%E4%BD%93%E7%9A%84%E3%81%AB)
    - [アウトを指定する](#%E3%82%A2%E3%82%A6%E3%83%88%E3%82%92%E6%8C%87%E5%AE%9A%E3%81%99%E3%82%8B)
    - [役割を明確にする](#%E5%BD%B9%E5%89%B2%E3%82%92%E6%98%8E%E7%A2%BA%E3%81%AB%E3%81%99%E3%82%8B)
    - [入出力例を与える](#%E5%85%A5%E5%87%BA%E5%8A%9B%E4%BE%8B%E3%82%92%E4%B8%8E%E3%81%88%E3%82%8B)
      - [Zero-shot LearningとFew-shot Learning](#zero-shot-learning%E3%81%A8few-shot-learning)
    - [構造的に書く](#%E6%A7%8B%E9%80%A0%E7%9A%84%E3%81%AB%E6%9B%B8%E3%81%8F)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

# 生成AI

大量のデータを学習することで、新たなコンテンツが生成できるようになったAIのこと

# 出力形式

ChatGPTが出力をjsonで返すことができるように、決まった形式で出力できると、そのままその結果をアプリケーションで組み込むことが簡単になる

# Code Interpreter

- ChatGPTに指示与える
- ChatGPTがその指示を解釈し、コードを生成
- 生成されたコードを実行
- 実行結果の解釈
- 追加で必要なコードを生成
- 生成されたコードを実行 ...
- 繰り返し

## Open Interpreter

Code Interpreterのオープンソース版。ローカルPC上でLLMと対話しながらLLMにコードが自校できる

# ハルシネーションの回避に注意

GPTは「確率的に確からしい返答」を行うので、実際に存在しない返答を行うことがある。これをハルシネーション（幻想）と呼ぶ。

- ユーザーがGPTの返答の妥当性を検証する
- 外部情報を参照して返答させるようなプロンプトエンジニアリングを行う

これらで回避を検討する

# ChatGPTと従来のちゃんとボットとの違い

柔軟性が高い。用意したパターンにとらわれず、回答文を生成する。それは、ChatGPTが「言語生成モデル」のため

# LLM

ChatGPTはLLMの一つ。GPTは Generative Pre-trained Transformer の略。大量のテキストデータを用いて事前学習を行うことで言語構造を解釈できるように調整（Pre -trained）されているため、Large Language Modelとも呼ばれる。大規模な言語モデルのこと。

# Transformer

ChatGPTはTransformerというモデルを用いている。Transformerから派生したモデルには、BERT、GPT、T5などがある。TransformerはAttention機構を用いて、文脈を考慮した言語モデルを構築することができる。

# スケール則

Transformerの性能は、

- モデルのパラメータ数
- モデルの学習データ量
- モデルの計算リソース

に比例して向上する。これをスケール則と呼ぶ。

# プロンプトエンジニアリング

入力をしてコンテンツを生成する生成AIへの入力し自分を「プロンプト」と呼ぶ。
プロンプトエンジニアリングとは、生成AIに対して、適切なプロンプトを与えることで、AIの出力をコントロールする技術のこと。

## プロンプトエンジニアリングのテクニック

基本的なテクニックがいくつかある

### 指示を具体的に

簡単な命令だと、AIが意図を理解できないことがある。具体的な指示を与えることで、AIが意図を理解しやすくなる。
例）「この文章を翻訳してください」よりも「この文章を英語に翻訳してください」と指示する

### アウトを指定する

逃げ道を与えると、余計な出力をしないようにすることができる。
例）

```
解答がわからない場合には、わかりませんとだけ返答してください
```

### 役割を明確にする

要約や推敲のタスクでは、AIにどのような役割を期待しているかを明確にすることが重要。
例）

```
あなたは機械学習の専門家です。この論文を中学生にもわかりやすく要約してください
```

### 入出力例を与える

AIに期待する入力と出力の例を与えることで、AIが期待通りの出力を行うようにする。

例）

```
ユーザーからの悩みの相談内容をもとに、適切な診療科を提案してください

入力：コロナワクチンを接種したい
出力：コロナワクチン接種

入力：自分の健康状態を知りたい
出力：健康診断

入力：歯が痛い
出力：歯科
```

#### Zero-shot LearningとFew-shot Learning

入出力例を与えずにシンプルな指示を粉うプロンプトのことをZero-shot Learningと呼ぶ。入出力例を与えるプロンプトのことをFew-shot Learningと呼ぶ。入出力例が1つだった場合には One-shot Learning と呼ぶ。

### 構造的に書く

プロンプトを構造的に書くことで、AIが期待通りの出力を行うようにする。
見出し、箇条書き、セクション区切りなどを駆使して、プロンプトを構造化することで、指示と条件と入力内容を区別しやすくなる。

例）

```
# 指示
あなたは機械学習の専門家です。これからいくつかの論文を遂行してもらいます。以下の条件を守ってそれらの論文を中学生にもわかりやすく要約してください。

# 条件
- 要約の長さは100文字以内
- 用語は中学生でも理解できるようにする
- 本文の内容をできるだけ網羅する
- 要約の文体は中学生向けにする

# 論文例
入力：xxxxxxxxxxx
出力：yyyyyyyyyyy

入力：xxxxxxxxxxx
出力：yyyyyyyyyyy
```
